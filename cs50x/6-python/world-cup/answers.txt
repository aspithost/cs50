Times:

10 simulations: 0m0.027s
100 simulations: 0m0.039s
1000 simulations: 0m0.040s
10000 simulations: 0m0.094s
100000 simulations: 0m0.817s
1000000 simulations: 0m7.203s

Questions:

Which predictions, if any, proved incorrect as you increased the number of simulations?:
I did not expect the real time to only start behaving in O(n) fashion after > 1000 simulations, I would have expected it to
perform that way from the start

Suppose you're charged a fee for each second of compute time your program uses.
After how many simulations would you call the predictions "good enough"?: After N=10000.
From there on out, simulations appear to become O(n) more expensive, while simulations appear to produce results not too far from what the assignment would suggest